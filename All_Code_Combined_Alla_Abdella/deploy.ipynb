{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading modules and  packages\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import Ridge\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "# Get the default datastore\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\n",
    "\n",
    "default_ds.upload_files(files=['./data/diabetes.csv'], # Upload the data/diabetes.csv file\n",
    "                       target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                       overwrite=True, # Replace existing files of the same name\n",
    "                       show_progress=True)\n",
    "                       \n",
    "from azureml.core import Dataset\n",
    "\n",
    "#Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/diabetes.csv'))\n",
    "\n",
    "# Display the first 20 rows as a Pandas dataframe\n",
    "data_set.take(20).to_pandas_dataframe()\n",
    "\n",
    "\n",
    "# Register the dataset\n",
    "dataset_name = 'Diabetes Dataset'\n",
    "data_set = data_set.register(workspace=ws, \n",
    "                           name=dataset_name,\n",
    "                           description='diabetes data',\n",
    "                           tags = {'year':'2019', 'category':'Diabetes'},\n",
    "                           create_new_version=True)\n",
    "\n",
    "# List the datasets registered in the workspace\n",
    "for ds in ws.datasets:\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace.create(name='xm-ml-workspace', subscription_id='be564fde-136b-4709-b7b6-abfc0bdfc134', resource_group='xm-ml')\n"
     ]
    }
   ],
   "source": [
    "print(ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model Based on Any Other Metric\n",
    "#Show the run and the model which has the smallest log_loss va\n",
    "lookup_metric = \"log_loss\"\n",
    "best_run, fitted_model = remote_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)\n",
    "\n",
    "# Model from a specfic iteration\n",
    "iteration = 1\n",
    "third_run, third_model = remote_run.get_output(iteration=iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class_models = Model.list(workspace=ws, tags=['area'])\n",
    "for m in class_models:\n",
    "    print(\"Name:\", m.name,\"\\tVersion:\", m.version, \"\\tDescription:\", m.description, m.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#registering the model\n",
    "model = Model.register(model_name = \"riskprediction\",\n",
    "                       model_path = \"model.pkl\",\n",
    "                       tags = {\"key\": \"1\",\"fraud\": \"riskpredict\"},\n",
    "                       description = \"riskpredictionanalysis\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{\"TOTAL_PRICE\":869.92,\"THIRD_PARTY_ID_SCORE\":415,\"IS_EXISTING_CUSTOMER\":\"Y\",\"NUM_PORTIN\":0,\"FIRST_PARTY_ID_SCORE\":356,\"ONETIMECHARGE\":33.33,\"INSTALLMENT_AMOUNT\":33.33,\"DEVICE_AT_HOME\":\"Y\",\"FRAUDNET_SCORE\":200.0,\"NUM_BYOD\":0,\"IDA_RESULT\":\"GREEN\",\"EXTERNAL_CREDIT_CHECK_DONE\":\"Y\",\"SALES_CHANNEL\":\"ONLINE\",\"MODEL1\":\"iPhone XR\",\"MODEL2\":\"NA\",\"MODEL3\":\"NA\",\"MODEL4\":\"NA\",\"MODEL5\":\"NA\"}])\n",
    "output_sample = np.array([0])\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # This name is model.id of model that we want to deploy deserialize the model file back\n",
    "    # into a sklearn model\n",
    "    model_path = Model.get_model_path(model_name = 'riskprediction')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        result = model.predict(data)\n",
    "        if result ==0:\n",
    "            result = 'GREEN'\n",
    "            print('GREEN')\n",
    "        elif result ==1:\n",
    "            result = 'YELLOW'\n",
    "            print('YELLOW')\n",
    "        else:\n",
    "            result = 'RED'\n",
    "            print('RED')\n",
    "        print('result') \n",
    "        fraud_status =[]\n",
    "        fraud_status.append(result)\n",
    "        return fraud_status\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\": result.tolist()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create environment file\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "fraudenv = CondaDependencies()\n",
    "fraudenv.add_conda_package(\"scikit-learn\")\n",
    "fraudenv.add_conda_package(\"numpy\")\n",
    "fraudenv.add_conda_package(\"scipy\")\n",
    "fraudenv.add_conda_package(\"pandas\")\n",
    "fraudenv.add_conda_package(\"py-xgboost<=0.80\")\n",
    "fraudenv.add_pip_package(\"azureml-defaults\")\n",
    "fraudenv.add_pip_package(\"azureml-train-automl==1.0.55\")\n",
    "fraudenv.add_pip_package(\"azureml-core==1.0.55\")\n",
    "fraudenv.add_pip_package(\"inference-schema\")\n",
    "fraudenv.conda_dependencies_file_path=\"data/env_dependencies.json\"\n",
    "with open(\"riskpredictionenv.yml\",\"w\") as f:\n",
    "    f.write(fraudenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e40af3fc09b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0maks_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'riskaks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Create the cluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m aks_target = ComputeTarget.create(workspace = ws,\n\u001b[0m\u001b[1;32m     13\u001b[0m                                     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maks_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                     provisioning_configuration = prov_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ws' is not defined"
     ]
    }
   ],
   "source": [
    "#create AKS cluster( its one time creation; No need to create for each deployment)\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Use the default configuration (you can also provide parameters to customize this).\n",
    "# For example, to create a dev/test cluster, use:\n",
    "# prov_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "prov_config.enable_ssl(leaf_domain_label = \"riskprediction\")\n",
    "\n",
    "aks_name = 'riskaks'\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws,\n",
    "                                    name = aks_name,\n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "# Wait for the create process to complete\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(aks_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a container image\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                 execution_script=\"score.py\",\n",
    "                                 conda_file=\"riskpredictionenv.yml\",\n",
    "                                 tags = {\"key\": \"1\"},\n",
    "                                 description = \"riskpredictionanalysis\")\n",
    "image = Image.create(name = \"riskprediction\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inference config\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"riskpredictionenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#service deployment\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "aks_target = AksCompute(ws,\"riskpredictdemo1\")\n",
    "\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1,enable_app_insights=True)\n",
    "service = Model.deploy(ws, \"riskpredictionanalysisnew\", [model] , inference_config, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deployment_config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The score uri:\",service.scoring_uri)\n",
    "print(\"The swagger:\", service.swagger_uri)\n",
    "primary, secondary = service.get_keys()\n",
    "print(\"the primary key:\",primary)\n",
    "print(\"the secondry key:\",secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#things to do\n",
    "how to retireve the existing AKS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
