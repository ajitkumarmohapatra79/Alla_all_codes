{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading modules and  packages\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "from sklearn.linear_model import Ridge\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remote_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-58dd232053de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mchildren\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mmetricslist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrun\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchildren\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remote_run' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core.run import Run\n",
    "\n",
    "run = Run.get_context()\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "target_names = ['Green', 'Yellow', 'Red']\n",
    "\n",
    "\n",
    "\n",
    "children = list(remote_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "AUC_weighted= rundata.loc['AUC_weighted'].max()\n",
    "run.log( \"AUC_weighted Max\",AUC_weighted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace.create(name='xm-ml-workspace', subscription_id='be564fde-136b-4709-b7b6-abfc0bdfc134', resource_group='xm-ml')\n"
     ]
    }
   ],
   "source": [
    "print(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model riskprediction\n"
     ]
    }
   ],
   "source": [
    "#registering the model\n",
    "model = Model.register(model_name = \"riskprediction\",\n",
    "                       model_path = \"data/riskprediction.pkl\",\n",
    "                       tags = {\"key\": \"1\",\"fraud\": \"riskpredict\"},\n",
    "                       description = \"riskpredictionanalysis\",\n",
    "                       workspace = ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(workspace=Workspace.create(name='xm-ml-workspace', subscription_id='be564fde-136b-4709-b7b6-abfc0bdfc134', resource_group='xm-ml'), name=riskprediction, id=riskprediction:10, version=10, tags={'key': '1', 'fraud': 'riskpredict'}, properties={})\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import azureml.train.automl\n",
    "from sklearn.externals import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "\n",
    "input_sample = pd.DataFrame(data=[{\"TOTAL_PRICE\":869.92,\"THIRD_PARTY_ID_SCORE\":415,\"IS_EXISTING_CUSTOMER\":\"Y\",\"NUM_PORTIN\":0,\"FIRST_PARTY_ID_SCORE\":356,\"ONETIMECHARGE\":33.33,\"INSTALLMENT_AMOUNT\":33.33,\"DEVICE_AT_HOME\":\"Y\",\"FRAUDNET_SCORE\":200.0,\"NUM_BYOD\":0,\"IDA_RESULT\":\"GREEN\",\"EXTERNAL_CREDIT_CHECK_DONE\":\"Y\",\"SALES_CHANNEL\":\"ONLINE\",\"MODEL1\":\"iPhone XR\",\"MODEL2\":\"NA\",\"MODEL3\":\"NA\",\"MODEL4\":\"NA\",\"MODEL5\":\"NA\"}])\n",
    "output_sample = np.array([0])\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    # This name is model.id of model that we want to deploy deserialize the model file back\n",
    "    # into a sklearn model\n",
    "    model_path = Model.get_model_path(model_name = 'riskprediction')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "@input_schema('data', PandasParameterType(input_sample))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        result = model.predict(data)\n",
    "        if result ==0:\n",
    "            result = 'GREEN'\n",
    "            print('GREEN')\n",
    "        elif result ==1:\n",
    "            result = 'YELLOW'\n",
    "            print('YELLOW')\n",
    "        else:\n",
    "            result = 'RED'\n",
    "            print('RED')\n",
    "        print('result') \n",
    "        fraud_status =[]\n",
    "        fraud_status.append(result)\n",
    "        return fraud_status\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return json.dumps({\"error\": result})\n",
    "    return json.dumps({\"result\": result.tolist()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create environment file\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.externals import joblib\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "from azureml.core import Experiment\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.image import ContainerImage\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "fraudenv = CondaDependencies()\n",
    "fraudenv.add_conda_package(\"scikit-learn\")\n",
    "fraudenv.add_conda_package(\"numpy\")\n",
    "fraudenv.add_conda_package(\"scipy\")\n",
    "fraudenv.add_conda_package(\"pandas\")\n",
    "fraudenv.add_conda_package(\"py-xgboost<=0.80\")\n",
    "fraudenv.add_pip_package(\"azureml-defaults\")\n",
    "fraudenv.add_pip_package(\"azureml-train-automl==1.0.55\")\n",
    "fraudenv.add_pip_package(\"azureml-core==1.0.55\")\n",
    "fraudenv.add_pip_package(\"inference-schema\")\n",
    "fraudenv.conda_dependencies_file_path=\"data/env_dependencies.json\"\n",
    "with open(\"riskpredictionenv.yml\",\"w\") as f:\n",
    "    f.write(fraudenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating..........................................................................................................................................................................\n",
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "#create AKS cluster( its one time creation; No need to create for each deployment)\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Use the default configuration (you can also provide parameters to customize this).\n",
    "# For example, to create a dev/test cluster, use:\n",
    "# prov_config = AksCompute.provisioning_configuration(cluster_purpose = AksCompute.ClusterPurpose.DEV_TEST)\n",
    "prov_config = AksCompute.provisioning_configuration()\n",
    "prov_config.enable_ssl(leaf_domain_label = \"riskprediction\")\n",
    "\n",
    "aks_name = 'riskpredictdemom'\n",
    "# Create the cluster\n",
    "aks_target = ComputeTarget.create(workspace = ws,\n",
    "                                    name = aks_name,\n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "# Wait for the create process to complete\n",
    "aks_target.wait_for_completion(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(aks_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image\n",
      "Running.....................................................\n",
      "Succeeded\n",
      "Image creation operation finished for image riskprediction:4, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "# creating a container image\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "image_config = ContainerImage.image_configuration(runtime= \"python\",\n",
    "                                 execution_script=\"score.py\",\n",
    "                                 conda_file=\"riskpredictionenv.yml\",\n",
    "                                 tags = {\"key\": \"1\"},\n",
    "                                 description = \"riskpredictionanalysis\")\n",
    "image = Image.create(name = \"riskprediction\",\n",
    "                     # this is the model object \n",
    "                     models = [model],\n",
    "                     image_config = image_config, \n",
    "                     workspace = ws)\n",
    "image.wait_for_creation(show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.core.image.container.ContainerImageConfig object at 0x7f5362a5c9b0>\n"
     ]
    }
   ],
   "source": [
    "print(image_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create inference config\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "inference_config = InferenceConfig(runtime= \"python\", \n",
    "                                   entry_script=\"score.py\",\n",
    "                                   conda_file=\"riskpredictionenv.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='ml-demo1-workspace', subscription_id='be564fde-136b-4709-b7b6-abfc0bdfc134', resource_group='xm-ml-demo'), name=riskprediction, id=riskprediction:2, version=2, tags={'key': '1', 'fraud': 'riskpredict'}, properties={})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running...\n",
      "SucceededAKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2019-10-07T15:51:32,364485657+00:00 - gunicorn/run \n",
      "2019-10-07T15:51:32,365829974+00:00 - rsyslog/run \n",
      "2019-10-07T15:51:32,365878575+00:00 - iot-server/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2019-10-07T15:51:32,372696861+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-10-07T15:51:32,442257439+00:00 - iot-server/finish 1 0\n",
      "2019-10-07T15:51:32,443932060+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-10-07 15:51:34,827 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}, switching offline: False\n",
      "2019-10-07 15:51:34,827 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-10-07 15:51:34,827 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "2019-10-07 15:51:34,827 | azureml.core.model | DEBUG | version is None. Latest version is 2\n",
      "2019-10-07 15:51:34,827 | azureml.core.model | DEBUG | Found model path at azureml-models/riskprediction/2/riskprediction.pkl\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#service deployment\n",
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.image import Image, ContainerImage\n",
    "\n",
    "aks_target = AksCompute(ws,\"riskpredictdemom\")\n",
    "\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1,enable_app_insights=True)\n",
    "service = Model.deploy(ws, \"riskpredictionanalysis\", [model] , inference_config, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<azureml.core.webservice.aks.AksServiceDeploymentConfiguration object at 0x7f53639d9e48>\n"
     ]
    }
   ],
   "source": [
    "print(deployment_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://riskpredictione28c4f.centralus.cloudapp.azure.com:443/api/v1/service/riskpredictionanalysis/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://riskpredictione28c4f.centralus.cloudapp.azure.com:443/api/v1/service/riskpredictionanalysis/swagger.json\n"
     ]
    }
   ],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-7e7821b0c6d6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-7e7821b0c6d6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    how to retireve the existing AKS information\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#things to do\n",
    "how to retireve the existing AKS information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2jbernuNuiY9MdQNKswPftthDBNOAIzO\n"
     ]
    }
   ],
   "source": [
    "primary, secondary = service.get_keys()\n",
    "print(primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2019-10-07T15:51:32,364485657+00:00 - gunicorn/run \n",
      "2019-10-07T15:51:32,365829974+00:00 - rsyslog/run \n",
      "2019-10-07T15:51:32,365878575+00:00 - iot-server/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2019-10-07T15:51:32,372696861+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_08ba8d0c58ba0617ee558bd9340a5830/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2019-10-07T15:51:32,442257439+00:00 - iot-server/finish 1 0\n",
      "2019-10-07T15:51:32,443932060+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (12)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 42\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "2019-10-07 15:51:34,827 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}, switching offline: False\n",
      "2019-10-07 15:51:34,827 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\n",
      "2019-10-07 15:51:34,827 | azureml.core.model | DEBUG | RunEnvironmentException: RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException RunEnvironmentException:\n",
      "\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\n",
      "\tInnerException None\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "\tErrorResponse {\"error\": {\"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"}}\n",
      "2019-10-07 15:51:34,827 | azureml.core.model | DEBUG | version is None. Latest version is 2\n",
      "2019-10-07 15:51:34,827 | azureml.core.model | DEBUG | Found model path at azureml-models/riskprediction/2/riskprediction.pkl\n",
      "Users's init has completed successfully\n",
      "Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xaEiceuTYEkyepxabpCYdnzsdvAvObUk\n"
     ]
    }
   ],
   "source": [
    "print(secondary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
